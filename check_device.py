import torch
import platform
import importlib.util

print("\nüîç Detecting Compute Device...\n")

# Check for NVIDIA (CUDA)
if torch.cuda.is_available():
    print("‚úÖ CUDA is available (NVIDIA GPU)")
    print(f"üöÄ CUDA Version : {torch.version.cuda}")
    print(f"üéÆ GPU Name     : {torch.cuda.get_device_name(0)}")

# Check for AMD (DirectML)
elif importlib.util.find_spec("torch_directml"):
    try:
        import torch_directml
        dml_device = torch_directml.device()
        # Try allocating a dummy tensor to confirm
        test_tensor = torch.empty((1,)).to(dml_device)
        print("‚úÖ DirectML is available (AMD GPU)")
        print(f"üñ•Ô∏è  DirectML Device: {dml_device}")
    except Exception as e:
        print("‚ö†Ô∏è Detected torch-directml, but could not initialize DirectML:", e)

# Fallback to CPU
else:
    print("‚ö†Ô∏è No GPU detected. Falling back to CPU execution.")
    print(f"üß† CPU Info: {platform.processor() or platform.machine()}")

print("\n‚úÖ Device check complete.")
